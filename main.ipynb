# üì¶ Step 1: Install Required Libraries
!pip install -q ultralytics transformers pillow

# üñºÔ∏è Step 2: Upload an Image
from google.colab import files
uploaded = files.upload()

image_path = list(uploaded.keys())[0]

# üîç Step 3: Object Detection using YOLOv8
from ultralytics import YOLO

# Load the YOLOv8 nano model
yolo_model = YOLO('yolov8n.pt')

# Run inference
detection_results = yolo_model(image_path)

# Extract detected objects with confidence scores
detected_objects = []
for result in detection_results:
    for box in result.boxes:
        class_name = result.names[int(box.cls[0])]
        confidence = float(box.conf[0])
        detected_objects.append((class_name, round(confidence, 2)))

print("‚úÖ Detected objects:", detected_objects)

# ‚ú® Step 4: Generate Text Using Flan-T5 (Free LLM)
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

# Load tokenizer and model
tokenizer = AutoTokenizer.from_pretrained("google/flan-t5-base")
llm_model = AutoModelForSeq2SeqLM.from_pretrained("google/flan-t5-base")

# Prompt user for input
user_prompt = input("üìù Enter your prompt: ")

# Format detected objects
object_summary = ", ".join([f"{obj} ({score*100:.1f}%)" for obj, score in detected_objects])
full_prompt = f"The image contains: {object_summary}. Based on this, {user_prompt}"

# Tokenize and generate text
inputs = tokenizer(full_prompt, return_tensors="pt", truncation=True)
outputs = llm_model.generate(**inputs, max_new_tokens=150)

# Decode and print result
response = tokenizer.decode(outputs[0], skip_special_tokens=True)
print("\nü§ñ LLM Response:\n")
print(response)
